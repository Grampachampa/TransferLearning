{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "import torch\n",
    "import torchrl\n",
    "from torchvision import transforms as T\n",
    "from tensordict import TensorDict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3) 0.0 False {'lives': 3, 'episode_frame_number': 4, 'frame_number': 4}\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/SpaceInvaders-v5\")\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(0)\n",
    "print(next_state.shape, reward, done, info)\n",
    "print(env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip Frame\n",
    "Every time we take an action, we repeat it for a certain number of frames. This emulates human input, where a person can not play frame-perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Skips frames for every action. Returns the sum of the rewards for the skipped frames.\n",
    "    \n",
    "    :param env: (gym.Env) The environment\n",
    "    :param skip: (int) The number of frames to skip\n",
    "    \"\"\"\n",
    "    def __init__(self, env, skip):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Repeat action, and sum reward\n",
    "        \n",
    "        :param action: (int) The action\n",
    "        :return: (tuple) The new observation, the sum of the rewards, the done flag, and additional information\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GrayScaleObeservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResizeObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SkipFrame(env, skip=2)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "\n",
    "num_stacks = 2\n",
    "\n",
    "env = gym.wrappers.FrameStack(env, num_stack=num_stacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Figure out online/training models, hyperparams\n",
    "\n",
    "class ZeroGameAgent:\n",
    "    def __init__(self, state_space, action_space, save_dir = None):\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.save_dir = save_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.net = ZeroGameNet(self.state_space, self.action_space).float().to(self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5\n",
    "\n",
    "        \n",
    "        self.memory = torchrl.data.TensorDictReplayBuffer(storage=torchrl.data.LazyMemmapStorage(100000, device=self.device))\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.9\n",
    "\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  \n",
    "\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "    \n",
    "    def act(self, state):\n",
    "        # Exploration\n",
    "        if random.random() < self.exploration_rate:\n",
    "            action = random.randint(0, self.action_space-1)\n",
    "        # Exploitation\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action = torch.argmax(action_values, axis=1).item()\n",
    "        \n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        self.curr_step += 1\n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        \n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()\n",
    "    \n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())\n",
    "    \n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"test_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"TestNet saved to {save_path} at step {self.curr_step}\")\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroGameNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim) \n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "    \n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(3136, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "zg = ZeroGameAgent(state_space=(num_stacks, 84, 84), action_space=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Step 251 - Epsilon 0.9999372519608879 - Mean Reward 195.0 - Mean Length 251.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 0.862 - Time 2024-03-05T14:42:19\n",
      "Episode 20 - Step 4850 - Epsilon 0.9987882346295732 - Mean Reward 116.429 - Mean Length 230.952 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 13.519 - Time 2024-03-05T14:42:32\n",
      "Episode 40 - Step 10086 - Epsilon 0.9974816759961261 - Mean Reward 126.707 - Mean Length 246.0 - Mean Loss 0.016 - Mean Q Value 0.001 - Time Delta 18.361 - Time 2024-03-05T14:42:50\n",
      "Episode 60 - Step 15382 - Epsilon 0.9961618839870565 - Mean Reward 133.361 - Mean Length 252.164 - Mean Loss 0.174 - Mean Q Value 0.013 - Time Delta 38.065 - Time 2024-03-05T14:43:28\n",
      "Episode 80 - Step 20688 - Epsilon 0.9948413511197547 - Mean Reward 138.148 - Mean Length 255.407 - Mean Loss 0.26 - Mean Q Value 0.022 - Time Delta 34.939 - Time 2024-03-05T14:44:03\n",
      "Episode 100 - Step 26025 - Epsilon 0.993514869007192 - Mean Reward 147.4 - Mean Length 257.74 - Mean Loss 0.314 - Mean Q Value 0.042 - Time Delta 33.814 - Time 2024-03-05T14:44:37\n",
      "Episode 120 - Step 31204 - Epsilon 0.9922293478635121 - Mean Reward 153.75 - Mean Length 263.54 - Mean Loss 0.421 - Mean Q Value 0.078 - Time Delta 36.117 - Time 2024-03-05T14:45:13\n",
      "Episode 140 - Step 36146 - Epsilon 0.9910042053385447 - Mean Reward 151.75 - Mean Length 260.6 - Mean Loss 0.527 - Mean Q Value 0.136 - Time Delta 31.907 - Time 2024-03-05T14:45:45\n",
      "Episode 160 - Step 40794 - Epsilon 0.9898533270976756 - Mean Reward 146.0 - Mean Length 254.12 - Mean Loss 0.526 - Mean Q Value 0.193 - Time Delta 31.769 - Time 2024-03-05T14:46:17\n",
      "Episode 180 - Step 45488 - Epsilon 0.9886924153712274 - Mean Reward 140.95 - Mean Length 248.0 - Mean Loss 0.522 - Mean Q Value 0.259 - Time Delta 31.767 - Time 2024-03-05T14:46:49\n",
      "Episode 200 - Step 50701 - Epsilon 0.9874047410827725 - Mean Reward 132.2 - Mean Length 246.76 - Mean Loss 0.514 - Mean Q Value 0.32 - Time Delta 33.505 - Time 2024-03-05T14:47:22\n",
      "Episode 220 - Step 56041 - Epsilon 0.9860874350859757 - Mean Reward 133.1 - Mean Length 248.37 - Mean Loss 0.515 - Mean Q Value 0.405 - Time Delta 35.091 - Time 2024-03-05T14:47:57\n",
      "Episode 240 - Step 61026 - Epsilon 0.9848592889138501 - Mean Reward 133.35 - Mean Length 248.8 - Mean Loss 0.499 - Mean Q Value 0.482 - Time Delta 30.162 - Time 2024-03-05T14:48:28\n",
      "Episode 260 - Step 65687 - Epsilon 0.9837123498490672 - Mean Reward 133.2 - Mean Length 248.93 - Mean Loss 0.506 - Mean Q Value 0.581 - Time Delta 32.655 - Time 2024-03-05T14:49:00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Agent performs action\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 14\u001b[0m     next_state, reward, done, trunc, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28mprint\u001b[39m(e)\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\gymnasium\\wrappers\\frame_stack.py:179\u001b[0m, in \u001b[0;36mFrameStack.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    171\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment, appending the observation to the frame buffer.\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \n\u001b[0;32m    173\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[38;5;124;03m        Stacked observations, reward, terminated, truncated, and information from the environment\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 179\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframes\u001b[38;5;241m.\u001b[39mappend(observation)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(\u001b[38;5;28;01mNone\u001b[39;00m), reward, terminated, truncated, info\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\gymnasium\\core.py:523\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    521\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Modifies the :attr:`env` after calling :meth:`step` using :meth:`self.observation` on the returned observations.\"\"\"\u001b[39;00m\n\u001b[0;32m    522\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m--> 523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m, reward, terminated, truncated, info\n",
      "Cell \u001b[1;32mIn[6], line 16\u001b[0m, in \u001b[0;36mResizeObservation.observation\u001b[1;34m(self, observation)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mobservation\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation):\n\u001b[0;32m     13\u001b[0m     transforms \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mCompose(\n\u001b[0;32m     14\u001b[0m         [T\u001b[38;5;241m.\u001b[39mResize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, antialias\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), T\u001b[38;5;241m.\u001b[39mNormalize(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m255\u001b[39m)]\n\u001b[0;32m     15\u001b[0m     )\n\u001b[1;32m---> 16\u001b[0m     observation \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observation\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torchvision\\transforms\\transforms.py:277\u001b[0m, in \u001b[0;36mNormalize.forward\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    270\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    271\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;124;03m        tensor (Tensor): Tensor image to be normalized.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;124;03m        Tensor: Normalized Tensor image.\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 277\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torchvision\\transforms\\functional.py:349\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimg should be Tensor Image. Got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 349\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstd\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:915\u001b[0m, in \u001b[0;36mnormalize\u001b[1;34m(tensor, mean, std, inplace)\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected tensor to be a tensor image of size (..., C, H, W). Got tensor.size() = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtensor\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m     )\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[1;32m--> 915\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    917\u001b[0m dtype \u001b[38;5;241m=\u001b[39m tensor\u001b[38;5;241m.\u001b[39mdtype\n\u001b[0;32m    918\u001b[0m mean \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mas_tensor(mean, dtype\u001b[38;5;241m=\u001b[39mdtype, device\u001b[38;5;241m=\u001b[39mtensor\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "episodes = 8000\n",
    "for e in range(episodes):\n",
    "   \n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = zg.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        try:\n",
    "            next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error in env.step. Last action:\", action)\n",
    "            break\n",
    "        # Remember\n",
    "        zg.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = zg.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done:\n",
    "            break\n",
    "        \n",
    "    logger.log_episode()\n",
    "    \n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=zg.exploration_rate, step=zg.curr_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gramp\\anaconda3\\envs\\cuda-env\\lib\\site-packages\\gymnasium\\core.py:311: UserWarning: \u001b[33mWARN: env.ale to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.ale` for environment variables or `env.get_wrapper_attr('ale')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# tenv = gym.make(\"ALE/SpaceInvaders-v5\", render_mode=\"human\")\n",
    "# tenv.reset()\n",
    "# tenv = SkipFrame(tenv, skip=4)\n",
    "# tenv = GrayScaleObservation(tenv)\n",
    "# tenv = ResizeObservation(tenv, shape=84)\n",
    "# tenv = gym.wrappers.FrameStack(tenv, num_stack=num_stacks)\n",
    "\n",
    "# episodes = 5\n",
    "# for e in range(episodes):\n",
    "   \n",
    "#     state = tenv.reset()\n",
    "\n",
    "#     # Play the game!\n",
    "#     while True:\n",
    "\n",
    "#         # Run agent on the state\n",
    "#         state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "#         state = torch.tensor(state, device=zg.device).unsqueeze(0)\n",
    "#         action_values = zg.net(state, model=\"online\")\n",
    "#         action = torch.argmax(action_values, axis=1).item()\n",
    "\n",
    "#         # Agent performs action\n",
    "#         try:\n",
    "#             next_state, reward, done, trunc, info = tenv.step(action)\n",
    "\n",
    "#         except Exception as e:\n",
    "#             print(e)\n",
    "#             print(\"Error in env.step. Last action:\", action)\n",
    "#             break\n",
    "        \n",
    "#         state = next_state\n",
    "\n",
    "#         # Check if end of game\n",
    "#         if done:\n",
    "#             break\n",
    "\n",
    "\n",
    "# # saving images\n",
    "\n",
    "# for i in range(state.shape[0]):\n",
    "#     img = state[i].cpu().numpy()\n",
    "#     plt.imshow(img, cmap=\"gray\")\n",
    "#     plt.savefig(f\"state_{i}.png\")\n",
    "\n",
    "# env.env.ale.saveScreenPNG('test_image2.png')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StableDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
