{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "import random\n",
    "import keras\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import transforms as T\n",
    "import torchrl\n",
    "from tensordict import TensorDict\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import time, datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a gym environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210, 160, 3) 0.0 False {'lives': 3, 'episode_frame_number': 4, 'frame_number': 4}\n",
      "['NOOP', 'FIRE', 'RIGHT', 'LEFT', 'RIGHTFIRE', 'LEFTFIRE']\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"ALE/SpaceInvaders-v5\")\n",
    "height, width, channels = env.observation_space.shape\n",
    "actions = env.action_space.n\n",
    "\n",
    "env.reset()\n",
    "next_state, reward, done, trunc, info = env.step(0)\n",
    "print(next_state.shape, reward, done, info)\n",
    "print(env.unwrapped.get_action_meanings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Skip Frame\n",
    "Every time we take an action, we repeat it for a certain number of frames. This emulates human input, where a person can not play frame-perfect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkipFrame(gym.Wrapper):\n",
    "    \"\"\"\n",
    "    Skips frames for every action. Returns the sum of the rewards for the skipped frames.\n",
    "    \n",
    "    :param env: (gym.Env) The environment\n",
    "    :param skip: (int) The number of frames to skip\n",
    "    \"\"\"\n",
    "    def __init__(self, env, skip):\n",
    "        super().__init__(env)\n",
    "        self._skip = skip\n",
    "    \n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        Repeat action, and sum reward\n",
    "        \n",
    "        :param action: (int) The action\n",
    "        :return: (tuple) The new observation, the sum of the rewards, the done flag, and additional information\n",
    "        \"\"\"\n",
    "        total_reward = 0.0\n",
    "        for i in range(self._skip):\n",
    "            # Accumulate reward and repeat the same action\n",
    "            obs, reward, done, trunk, info = self.env.step(action)\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        return obs, total_reward, done, trunk, info\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### GrayScaleObeservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GrayScaleObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super().__init__(env)\n",
    "        obs_shape = self.observation_space.shape[:2]\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def permute_orientation(self, observation):\n",
    "        # permute [H, W, C] array to [C, H, W] tensor\n",
    "        observation = np.transpose(observation, (2, 0, 1))\n",
    "        observation = torch.tensor(observation.copy(), dtype=torch.float)\n",
    "        return observation\n",
    "\n",
    "    def observation(self, observation):\n",
    "        observation = self.permute_orientation(observation)\n",
    "        transform = T.Grayscale()\n",
    "        observation = transform(observation)\n",
    "        return observation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### ResizeObservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResizeObservation(gym.ObservationWrapper):\n",
    "    def __init__(self, env, shape):\n",
    "        super().__init__(env)\n",
    "        if isinstance(shape, int):\n",
    "            self.shape = (shape, shape)\n",
    "        else:\n",
    "            self.shape = tuple(shape)\n",
    "\n",
    "        obs_shape = self.shape + self.observation_space.shape[2:]\n",
    "        self.observation_space = gym.spaces.Box(low=0, high=255, shape=obs_shape, dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        transforms = T.Compose(\n",
    "            [T.Resize(self.shape, antialias=True), T.Normalize(0, 255)]\n",
    "        )\n",
    "        observation = transforms(observation).squeeze(0)\n",
    "        return observation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = SkipFrame(env, skip=4)\n",
    "env = GrayScaleObservation(env)\n",
    "env = ResizeObservation(env, shape=84)\n",
    "env = gym.wrappers.FrameStack(env, num_stack=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroGameAgent:\n",
    "    def __init__(self, state_space, action_space, save_dir = None):\n",
    "\n",
    "        self.action_space = action_space\n",
    "        self.state_space = state_space\n",
    "        self.save_dir = save_dir\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        self.net = ZeroGameNet(self.state_space, self.action_space).float().to(self.device)\n",
    "\n",
    "        self.exploration_rate = 1\n",
    "        self.exploration_rate_decay = 0.99999975\n",
    "        self.exploration_rate_min = 0.1\n",
    "        self.curr_step = 0\n",
    "\n",
    "        self.save_every = 5e5\n",
    "\n",
    "        self.memory = torchrl.data.TensorDictReplayBuffer(storage=torchrl.data.LazyMemmapStorage(100000, device=torch.device(\"cpu\")))\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.9\n",
    "\n",
    "        self.burnin = 1e4  # min. experiences before training\n",
    "        self.learn_every = 3  # no. of experiences between updates to Q_online\n",
    "        self.sync_every = 1e4  \n",
    "\n",
    "\n",
    "        self.optimizer = torch.optim.Adam(self.net.parameters(), lr=0.00025)\n",
    "        self.loss_fn = torch.nn.SmoothL1Loss()\n",
    "    \n",
    "    def act(self, state):\n",
    "        # Exploration\n",
    "        if random.random() < self.exploration_rate:\n",
    "            action = random.randint(0, self.action_space-1)\n",
    "        # Exploitation\n",
    "        else:\n",
    "            state = state[0].__array__() if isinstance(state, tuple) else state.__array__()\n",
    "            state = torch.tensor(state, device=self.device).unsqueeze(0)\n",
    "            action_values = self.net(state, model=\"online\")\n",
    "            action = torch.argmax(action_values, axis=1).item()\n",
    "        \n",
    "        self.exploration_rate *= self.exploration_rate_decay\n",
    "        self.exploration_rate = max(self.exploration_rate_min, self.exploration_rate)\n",
    "\n",
    "        self.curr_step += 1\n",
    "        return action\n",
    "    \n",
    "    def cache(self, state, next_state, action, reward, done):\n",
    "        \"\"\"\n",
    "        Store the experience to self.memory (replay buffer)\n",
    "\n",
    "        Inputs:\n",
    "        state (``LazyFrame``),\n",
    "        next_state (``LazyFrame``),\n",
    "        action (``int``),\n",
    "        reward (``float``),\n",
    "        done(``bool``))\n",
    "        \"\"\"\n",
    "        def first_if_tuple(x):\n",
    "            return x[0] if isinstance(x, tuple) else x\n",
    "        \n",
    "        state = first_if_tuple(state).__array__()\n",
    "        next_state = first_if_tuple(next_state).__array__()\n",
    "\n",
    "        state = torch.tensor(state)\n",
    "        next_state = torch.tensor(next_state)\n",
    "        action = torch.tensor([action])\n",
    "        reward = torch.tensor([reward])\n",
    "        done = torch.tensor([done])\n",
    "\n",
    "        self.memory.add(TensorDict({\"state\": state, \"next_state\": next_state, \"action\": action, \"reward\": reward, \"done\": done}, batch_size=[]))\n",
    "\n",
    "    def recall(self):\n",
    "        \"\"\"\n",
    "        Retrieve a batch of experiences from memory\n",
    "        \"\"\"\n",
    "        batch = self.memory.sample(self.batch_size).to(self.device)\n",
    "        state, next_state, action, reward, done = (batch.get(key) for key in (\"state\", \"next_state\", \"action\", \"reward\", \"done\"))\n",
    "        return state, next_state, action.squeeze(), reward.squeeze(), done.squeeze()\n",
    "\n",
    "    def td_estimate(self, state, action):\n",
    "        current_Q = self.net(state, model=\"online\")[\n",
    "            np.arange(0, self.batch_size), action\n",
    "        ]  # Q_online(s,a)\n",
    "        return current_Q\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def td_target(self, reward, next_state, done):\n",
    "        next_state_Q = self.net(next_state, model=\"online\")\n",
    "        best_action = torch.argmax(next_state_Q, axis=1)\n",
    "        next_Q = self.net(next_state, model=\"target\")[\n",
    "            np.arange(0, self.batch_size), best_action\n",
    "        ]\n",
    "        return (reward + (1 - done.float()) * self.gamma * next_Q).float()\n",
    "    \n",
    "    def update_Q_online(self, td_estimate, td_target):\n",
    "        loss = self.loss_fn(td_estimate, td_target)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss.item()\n",
    "\n",
    "    def sync_Q_target(self):\n",
    "        self.net.target.load_state_dict(self.net.online.state_dict())\n",
    "    \n",
    "    def save(self):\n",
    "        save_path = (\n",
    "            self.save_dir / f\"test_net_{int(self.curr_step // self.save_every)}.chkpt\"\n",
    "        )\n",
    "        torch.save(\n",
    "            dict(model=self.net.state_dict(), exploration_rate=self.exploration_rate),\n",
    "            save_path,\n",
    "        )\n",
    "        print(f\"TestNet saved to {save_path} at step {self.curr_step}\")\n",
    "    \n",
    "    def learn(self):\n",
    "        if self.curr_step % self.sync_every == 0:\n",
    "            self.sync_Q_target()\n",
    "\n",
    "        if self.curr_step % self.save_every == 0:\n",
    "            self.save()\n",
    "\n",
    "        if self.curr_step < self.burnin:\n",
    "            return None, None\n",
    "\n",
    "        if self.curr_step % self.learn_every != 0:\n",
    "            return None, None\n",
    "\n",
    "        # Sample from memory\n",
    "        state, next_state, action, reward, done = self.recall()\n",
    "\n",
    "        # Get TD Estimate\n",
    "        td_est = self.td_estimate(state, action)\n",
    "\n",
    "        # Get TD Target\n",
    "        td_tgt = self.td_target(reward, next_state, done)\n",
    "\n",
    "        # Backpropagate loss through Q_online\n",
    "        loss = self.update_Q_online(td_est, td_tgt)\n",
    "\n",
    "        return (td_est.mean().item(), loss)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroGameNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim) \n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "    \n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(3136, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroGameNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim) \n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "    \n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(3136, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroGameNet(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        c, h, w = input_dim\n",
    "\n",
    "        if h != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {h}\")\n",
    "        if w != 84:\n",
    "            raise ValueError(f\"Expecting input height: 84, got: {w}\")\n",
    "\n",
    "        self.online = self.__build_cnn(c, output_dim)\n",
    "\n",
    "        self.target = self.__build_cnn(c, output_dim) \n",
    "        self.target.load_state_dict(self.online.state_dict())\n",
    "\n",
    "        for p in self.target.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "    \n",
    "    def forward(self, input, model):\n",
    "        if model == \"online\":\n",
    "            return self.online(input)\n",
    "        elif model == \"target\":\n",
    "            return self.target(input)\n",
    "    \n",
    "    def __build_cnn(self, c, output_dim):\n",
    "        return torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(in_channels=c, out_channels=32, kernel_size=8, stride=4),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=32, out_channels=64, kernel_size=4, stride=2),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Flatten(),\n",
    "            torch.nn.Linear(3136, 512),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(512, output_dim),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLogger:\n",
    "    def __init__(self, save_dir):\n",
    "        self.save_log = save_dir / \"log\"\n",
    "        with open(self.save_log, \"w\") as f:\n",
    "            f.write(\n",
    "                f\"{'Episode':>8}{'Step':>8}{'Epsilon':>10}{'MeanReward':>15}\"\n",
    "                f\"{'MeanLength':>15}{'MeanLoss':>15}{'MeanQValue':>15}\"\n",
    "                f\"{'TimeDelta':>15}{'Time':>20}\\n\"\n",
    "            )\n",
    "        self.ep_rewards_plot = save_dir / \"reward_plot.jpg\"\n",
    "        self.ep_lengths_plot = save_dir / \"length_plot.jpg\"\n",
    "        self.ep_avg_losses_plot = save_dir / \"loss_plot.jpg\"\n",
    "        self.ep_avg_qs_plot = save_dir / \"q_plot.jpg\"\n",
    "\n",
    "        # History metrics\n",
    "        self.ep_rewards = []\n",
    "        self.ep_lengths = []\n",
    "        self.ep_avg_losses = []\n",
    "        self.ep_avg_qs = []\n",
    "\n",
    "        # Moving averages, added for every call to record()\n",
    "        self.moving_avg_ep_rewards = []\n",
    "        self.moving_avg_ep_lengths = []\n",
    "        self.moving_avg_ep_avg_losses = []\n",
    "        self.moving_avg_ep_avg_qs = []\n",
    "\n",
    "        # Current episode metric\n",
    "        self.init_episode()\n",
    "\n",
    "        # Timing\n",
    "        self.record_time = time.time()\n",
    "\n",
    "    def log_step(self, reward, loss, q):\n",
    "        self.curr_ep_reward += reward\n",
    "        self.curr_ep_length += 1\n",
    "        if loss:\n",
    "            self.curr_ep_loss += loss\n",
    "            self.curr_ep_q += q\n",
    "            self.curr_ep_loss_length += 1\n",
    "\n",
    "    def log_episode(self):\n",
    "        \"Mark end of episode\"\n",
    "        self.ep_rewards.append(self.curr_ep_reward)\n",
    "        self.ep_lengths.append(self.curr_ep_length)\n",
    "        if self.curr_ep_loss_length == 0:\n",
    "            ep_avg_loss = 0\n",
    "            ep_avg_q = 0\n",
    "        else:\n",
    "            ep_avg_loss = np.round(self.curr_ep_loss / self.curr_ep_loss_length, 5)\n",
    "            ep_avg_q = np.round(self.curr_ep_q / self.curr_ep_loss_length, 5)\n",
    "        self.ep_avg_losses.append(ep_avg_loss)\n",
    "        self.ep_avg_qs.append(ep_avg_q)\n",
    "\n",
    "        self.init_episode()\n",
    "\n",
    "    def init_episode(self):\n",
    "        self.curr_ep_reward = 0.0\n",
    "        self.curr_ep_length = 0\n",
    "        self.curr_ep_loss = 0.0\n",
    "        self.curr_ep_q = 0.0\n",
    "        self.curr_ep_loss_length = 0\n",
    "\n",
    "    def record(self, episode, epsilon, step):\n",
    "        mean_ep_reward = np.round(np.mean(self.ep_rewards[-100:]), 3)\n",
    "        mean_ep_length = np.round(np.mean(self.ep_lengths[-100:]), 3)\n",
    "        mean_ep_loss = np.round(np.mean(self.ep_avg_losses[-100:]), 3)\n",
    "        mean_ep_q = np.round(np.mean(self.ep_avg_qs[-100:]), 3)\n",
    "        self.moving_avg_ep_rewards.append(mean_ep_reward)\n",
    "        self.moving_avg_ep_lengths.append(mean_ep_length)\n",
    "        self.moving_avg_ep_avg_losses.append(mean_ep_loss)\n",
    "        self.moving_avg_ep_avg_qs.append(mean_ep_q)\n",
    "\n",
    "        last_record_time = self.record_time\n",
    "        self.record_time = time.time()\n",
    "        time_since_last_record = np.round(self.record_time - last_record_time, 3)\n",
    "\n",
    "        print(\n",
    "            f\"Episode {episode} - \"\n",
    "            f\"Step {step} - \"\n",
    "            f\"Epsilon {epsilon} - \"\n",
    "            f\"Mean Reward {mean_ep_reward} - \"\n",
    "            f\"Mean Length {mean_ep_length} - \"\n",
    "            f\"Mean Loss {mean_ep_loss} - \"\n",
    "            f\"Mean Q Value {mean_ep_q} - \"\n",
    "            f\"Time Delta {time_since_last_record} - \"\n",
    "            f\"Time {datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S')}\"\n",
    "        )\n",
    "\n",
    "        with open(self.save_log, \"a\") as f:\n",
    "            f.write(\n",
    "                f\"{episode:8d}{step:8d}{epsilon:10.3f}\"\n",
    "                f\"{mean_ep_reward:15.3f}{mean_ep_length:15.3f}{mean_ep_loss:15.3f}{mean_ep_q:15.3f}\"\n",
    "                f\"{time_since_last_record:15.3f}\"\n",
    "                f\"{datetime.datetime.now().strftime('%Y-%m-%dT%H:%M:%S'):>20}\\n\"\n",
    "            )\n",
    "\n",
    "        for metric in [\"ep_lengths\", \"ep_avg_losses\", \"ep_avg_qs\", \"ep_rewards\"]:\n",
    "            plt.clf()\n",
    "            plt.plot(getattr(self, f\"moving_avg_{metric}\"), label=f\"moving_avg_{metric}\")\n",
    "            plt.legend()\n",
    "            plt.savefig(getattr(self, f\"{metric}_plot\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA: False\n",
      "\n",
      "Episode 0 - Step 120 - Epsilon 0.9999700004462413 - Mean Reward 85.0 - Mean Length 120.0 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 0.945 - Time 2024-03-02T23:21:57\n",
      "Episode 20 - Step 3080 - Epsilon 0.9992302962776419 - Mean Reward 195.952 - Mean Length 146.667 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 13.289 - Time 2024-03-02T23:22:10\n",
      "Episode 40 - Step 5669 - Epsilon 0.9985837536473994 - Mean Reward 173.049 - Mean Length 138.268 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 11.702 - Time 2024-03-02T23:22:22\n",
      "Episode 60 - Step 8310 - Epsilon 0.9979246562500431 - Mean Reward 161.23 - Mean Length 136.23 - Mean Loss 0.0 - Mean Q Value 0.0 - Time Delta 14.753 - Time 2024-03-02T23:22:36\n",
      "Episode 80 - Step 10934 - Epsilon 0.997270232268183 - Mean Reward 158.519 - Mean Length 134.988 - Mean Loss 0.112 - Mean Q Value 0.009 - Time Delta 26.109 - Time 2024-03-02T23:23:03\n",
      "Episode 100 - Step 13808 - Epsilon 0.9965539508715692 - Mean Reward 160.1 - Mean Length 136.88 - Mean Loss 0.32 - Mean Q Value 0.024 - Time Delta 55.92 - Time 2024-03-02T23:23:59\n",
      "Episode 120 - Step 16455 - Epsilon 0.9958946993659811 - Mean Reward 145.05 - Mean Length 133.75 - Mean Loss 0.552 - Mean Q Value 0.042 - Time Delta 58.313 - Time 2024-03-02T23:24:57\n",
      "Episode 140 - Step 19211 - Epsilon 0.9952087641640929 - Mean Reward 144.85 - Mean Length 135.42 - Mean Loss 0.765 - Mean Q Value 0.061 - Time Delta 69.042 - Time 2024-03-02T23:26:06\n",
      "Episode 160 - Step 21719 - Epsilon 0.9945849637727585 - Mean Reward 142.7 - Mean Length 134.09 - Mean Loss 0.969 - Mean Q Value 0.092 - Time Delta 60.188 - Time 2024-03-02T23:27:06\n",
      "Episode 180 - Step 24300 - Epsilon 0.9939434147466129 - Mean Reward 138.35 - Mean Length 133.66 - Mean Loss 1.08 - Mean Q Value 0.128 - Time Delta 64.009 - Time 2024-03-02T23:28:10\n",
      "Episode 200 - Step 26649 - Epsilon 0.9933598927566952 - Mean Reward 121.35 - Mean Length 128.41 - Mean Loss 1.049 - Mean Q Value 0.163 - Time Delta 55.047 - Time 2024-03-02T23:29:05\n",
      "Episode 220 - Step 29221 - Epsilon 0.9927213675735955 - Mean Reward 124.1 - Mean Length 127.66 - Mean Loss 1.011 - Mean Q Value 0.203 - Time Delta 59.503 - Time 2024-03-02T23:30:05\n",
      "Episode 240 - Step 31928 - Epsilon 0.9920497705813095 - Mean Reward 123.8 - Mean Length 127.17 - Mean Loss 0.994 - Mean Q Value 0.266 - Time Delta 65.644 - Time 2024-03-02T23:31:10\n",
      "Episode 260 - Step 34288 - Epsilon 0.9914646337757735 - Mean Reward 121.7 - Mean Length 125.69 - Mean Loss 0.989 - Mean Q Value 0.332 - Time Delta 55.009 - Time 2024-03-02T23:32:05\n",
      "Episode 280 - Step 36701 - Epsilon 0.990866713026598 - Mean Reward 118.05 - Mean Length 124.01 - Mean Loss 0.971 - Mean Q Value 0.388 - Time Delta 56.873 - Time 2024-03-02T23:33:02\n",
      "Episode 300 - Step 38972 - Epsilon 0.9903043080477189 - Mean Reward 125.2 - Mean Length 123.23 - Mean Loss 0.956 - Mean Q Value 0.438 - Time Delta 56.547 - Time 2024-03-02T23:33:59\n",
      "Episode 320 - Step 41475 - Epsilon 0.9896848188923183 - Mean Reward 124.25 - Mean Length 122.54 - Mean Loss 0.947 - Mean Q Value 0.517 - Time Delta 56.764 - Time 2024-03-02T23:34:55\n",
      "Episode 340 - Step 43914 - Epsilon 0.9890815424411006 - Mean Reward 117.85 - Mean Length 119.86 - Mean Loss 0.946 - Mean Q Value 0.588 - Time Delta 58.25 - Time 2024-03-02T23:35:54\n",
      "Episode 360 - Step 46236 - Epsilon 0.9885075471521363 - Mean Reward 112.1 - Mean Length 119.48 - Mean Loss 0.959 - Mean Q Value 0.641 - Time Delta 55.515 - Time 2024-03-02T23:36:49\n",
      "Episode 380 - Step 48639 - Epsilon 0.9879138795096668 - Mean Reward 112.5 - Mean Length 119.38 - Mean Loss 0.961 - Mean Q Value 0.698 - Time Delta 59.812 - Time 2024-03-02T23:37:49\n",
      "Episode 400 - Step 51411 - Epsilon 0.9872294922730913 - Mean Reward 122.2 - Mean Length 124.39 - Mean Loss 0.968 - Mean Q Value 0.783 - Time Delta 80.432 - Time 2024-03-02T23:39:09\n",
      "Episode 420 - Step 53854 - Epsilon 0.986626725873781 - Mean Reward 115.5 - Mean Length 123.79 - Mean Loss 0.984 - Mean Q Value 0.862 - Time Delta 65.921 - Time 2024-03-02T23:40:15\n",
      "Episode 440 - Step 56263 - Epsilon 0.9860327087451501 - Mean Reward 114.45 - Mean Length 123.49 - Mean Loss 0.984 - Mean Q Value 0.927 - Time Delta 59.101 - Time 2024-03-02T23:41:14\n",
      "Episode 460 - Step 58865 - Epsilon 0.9853915029626611 - Mean Reward 127.0 - Mean Length 126.29 - Mean Loss 0.959 - Mean Q Value 0.994 - Time Delta 72.951 - Time 2024-03-02T23:42:27\n",
      "Episode 480 - Step 61439 - Epsilon 0.9847576074289424 - Mean Reward 139.55 - Mean Length 128.0 - Mean Loss 0.988 - Mean Q Value 1.14 - Time Delta 68.097 - Time 2024-03-02T23:43:36\n",
      "Episode 500 - Step 64015 - Epsilon 0.984123627613834 - Mean Reward 132.35 - Mean Length 126.04 - Mean Loss 1.009 - Mean Q Value 1.305 - Time Delta 74.116 - Time 2024-03-02T23:44:50\n",
      "Episode 520 - Step 66786 - Epsilon 0.9834421119727573 - Mean Reward 143.95 - Mean Length 129.32 - Mean Loss 1.021 - Mean Q Value 1.44 - Time Delta 96.219 - Time 2024-03-02T23:46:26\n",
      "Episode 540 - Step 69775 - Epsilon 0.9827075092627792 - Mean Reward 155.45 - Mean Length 135.12 - Mean Loss 1.029 - Mean Q Value 1.584 - Time Delta 222.072 - Time 2024-03-02T23:50:08\n",
      "Episode 560 - Step 72101 - Epsilon 0.9821362308899391 - Mean Reward 147.95 - Mean Length 132.36 - Mean Loss 1.068 - Mean Q Value 1.827 - Time Delta 78.817 - Time 2024-03-02T23:51:27\n",
      "Episode 580 - Step 74301 - Epsilon 0.9815962044162644 - Mean Reward 131.8 - Mean Length 128.62 - Mean Loss 1.072 - Mean Q Value 2.01 - Time Delta 66.348 - Time 2024-03-02T23:52:33\n",
      "Episode 600 - Step 76931 - Epsilon 0.980951016959741 - Mean Reward 136.25 - Mean Length 129.16 - Mean Loss 1.064 - Mean Q Value 2.134 - Time Delta 92.182 - Time 2024-03-02T23:54:05\n",
      "Episode 620 - Step 79649 - Epsilon 0.9802846870715508 - Mean Reward 138.5 - Mean Length 128.63 - Mean Loss 1.071 - Mean Q Value 2.27 - Time Delta 86.059 - Time 2024-03-02T23:55:31\n",
      "Episode 640 - Step 81944 - Epsilon 0.9797224099806449 - Mean Reward 125.3 - Mean Length 121.69 - Mean Loss 1.09 - Mean Q Value 2.481 - Time Delta 71.401 - Time 2024-03-02T23:56:43\n",
      "Episode 660 - Step 84735 - Epsilon 0.9790390470195423 - Mean Reward 128.55 - Mean Length 126.34 - Mean Loss 1.083 - Mean Q Value 2.628 - Time Delta 89.574 - Time 2024-03-02T23:58:12\n",
      "Episode 680 - Step 87461 - Epsilon 0.9783720591274733 - Mean Reward 135.45 - Mean Length 131.6 - Mean Loss 1.097 - Mean Q Value 2.749 - Time Delta 87.614 - Time 2024-03-02T23:59:40\n",
      "Episode 700 - Step 90205 - Epsilon 0.977701125967337 - Mean Reward 144.5 - Mean Length 132.74 - Mean Loss 1.117 - Mean Q Value 2.892 - Time Delta 94.233 - Time 2024-03-03T00:01:14\n",
      "Episode 720 - Step 92881 - Epsilon 0.9770472625739327 - Mean Reward 136.8 - Mean Length 132.32 - Mean Loss 1.147 - Mean Q Value 3.136 - Time Delta 99.109 - Time 2024-03-03T00:02:53\n",
      "Episode 740 - Step 95752 - Epsilon 0.9763462384236332 - Mean Reward 150.75 - Mean Length 138.08 - Mean Loss 1.147 - Mean Q Value 3.283 - Time Delta 122.092 - Time 2024-03-03T00:04:55\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m zg\u001b[38;5;241m.\u001b[39mcache(state, next_state, action, reward, done)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Learn\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m q, loss \u001b[38;5;241m=\u001b[39m \u001b[43mzg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Logging\u001b[39;00m\n\u001b[0;32m     37\u001b[0m logger\u001b[38;5;241m.\u001b[39mlog_step(reward, loss, q)\n",
      "Cell \u001b[1;32mIn[7], line 138\u001b[0m, in \u001b[0;36mZeroGameAgent.learn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m td_tgt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtd_target(reward, next_state, done)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;66;03m# Backpropagate loss through Q_online\u001b[39;00m\n\u001b[1;32m--> 138\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_Q_online\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtd_est\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtd_tgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (td_est\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39mitem(), loss)\n",
      "Cell \u001b[1;32mIn[7], line 99\u001b[0m, in \u001b[0;36mZeroGameAgent.update_Q_online\u001b[1;34m(self, td_estimate, td_target)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     98\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\torch\\optim\\optimizer.py:385\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    381\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    382\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    383\u001b[0m             )\n\u001b[1;32m--> 385\u001b[0m out \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[0;32m    388\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     74\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     75\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[1;32m---> 76\u001b[0m     ret \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\torch\\optim\\adam.py:166\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    155\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    157\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[0;32m    158\u001b[0m         group,\n\u001b[0;32m    159\u001b[0m         params_with_grad,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    163\u001b[0m         max_exp_avg_sqs,\n\u001b[0;32m    164\u001b[0m         state_steps)\n\u001b[1;32m--> 166\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\torch\\optim\\adam.py:316\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    314\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 316\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    323\u001b[0m \u001b[43m     \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m     \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m     \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\gramp\\anaconda3\\envs\\StableDiff\\lib\\site-packages\\torch\\optim\\adam.py:441\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    438\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    439\u001b[0m         denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m bias_correction2_sqrt)\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m--> 441\u001b[0m     \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    443\u001b[0m \u001b[38;5;66;03m# Lastly, switch back to complex view\u001b[39;00m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m amsgrad \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mis_complex(params[i]):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "print(f\"Using CUDA: {use_cuda}\")\n",
    "print()\n",
    "\n",
    "save_dir = Path(\"checkpoints\") / datetime.datetime.now().strftime(\"%Y-%m-%dT%H-%M-%S\")\n",
    "save_dir.mkdir(parents=True)\n",
    "zg = ZeroGameAgent(state_space=(4, 84, 84), action_space=env.action_space.n, save_dir=save_dir)\n",
    "\n",
    "logger = MetricLogger(save_dir)\n",
    "\n",
    "episodes = 4000\n",
    "for e in range(episodes):\n",
    "\n",
    "    state = env.reset()\n",
    "\n",
    "    # Play the game!\n",
    "    while True:\n",
    "\n",
    "        # Run agent on the state\n",
    "        action = zg.act(state)\n",
    "\n",
    "        # Agent performs action\n",
    "        try:\n",
    "            next_state, reward, done, trunc, info = env.step(action)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(\"Error in env.step. Last action:\", action)\n",
    "            break\n",
    "        # Remember\n",
    "        zg.cache(state, next_state, action, reward, done)\n",
    "\n",
    "        # Learn\n",
    "        q, loss = zg.learn()\n",
    "\n",
    "        # Logging\n",
    "        logger.log_step(reward, loss, q)\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Check if end of game\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    logger.log_episode()\n",
    "\n",
    "    if (e % 20 == 0) or (e == episodes - 1):\n",
    "        logger.record(episode=e, epsilon=zg.exploration_rate, step=zg.curr_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StableDiff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
